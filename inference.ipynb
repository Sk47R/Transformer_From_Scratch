{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from config import get_config, latest_weights_file_path\n",
    "from train import get_model, get_ds, run_validation\n",
    "from translate import translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Max length of source sentence: 309\n",
      "Max length of target sentence: 274\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DEFINE THE DEVICE\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# GET THE CONFIGURATION\n",
    "config = get_config()\n",
    "train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt = get_ds(config)\n",
    "model = get_model(config, tokenizer_src.get_vocab_size(), tokenizer_tgt.get_vocab_size()).to(device)\n",
    "\n",
    "# LOAD THE PRETRAINED WEiGHTS\n",
    "model_filename = latest_weights_file_path(config)\n",
    "state = torch.load(model_filename)\n",
    "model.load_state_dict(state['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: 'Love match!\n",
      "    TARGET: — D’amore?\n",
      " PREDICTED: — D ’ amore ?\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: I take no interest in creeping round dim and chilly churches behind wheezy old men, and reading epitaphs.\n",
      "    TARGET: Non m’interessa affatto vagare in chiese tristi e fredde dietro dei vecchi asmatici a leggere epitaffi.\n",
      " PREDICTED: Non vi debba far altro che gente tristi e fredde dietro dei vecchi a leggere epitaffi .\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: So you see, Miss, we're doing our best, afore she comes, to--' At this moment Five, who had been anxiously looking across the garden, called out 'The Queen!\n",
      "    TARGET: Se la Regina se ne avvedesse, ci farebbe tagliare le teste a tutti. Così, signorina, facciamo il possibile per rimediare prima ch'essa venga a...\n",
      " PREDICTED: Se la Regina se ne avvedesse , ci farebbe tagliare le teste a tutti , signorina , facciamo subito la possibile per rimediare prima ch ' essa venga a ...\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: I was noting these things and enjoying them as a child might, when it entered my mind as it had never done before:--\n",
      "    TARGET: Osservai tutte quelle cose e ne godei, come ne può godere una bimba, e il mio spirito si fermò a fare una considerazione non mai fatta prima.\n",
      " PREDICTED: Osservai tutte quelle cose e ne , come ne può godere una bimba , e il mio spirito si fermò a fare una considerazione non mai fatta prima .\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: \"But you comprehend me?\" he said.\n",
      "    TARGET: — Ma mi avete capito bene? — riprese.\n",
      " PREDICTED: — Ma mi avete capito bene ? — domandò .\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: 'Perhaps,' said Vronsky.\n",
      "    TARGET: — Può darsi — rispose Vronskij.\n",
      " PREDICTED: — Può darsi — rispose Vronskij .\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: It is torture!\n",
      "    TARGET: È un tormento!\n",
      " PREDICTED: Mi è un tormento !\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: While Betsy was pouring out the tea, Vronsky went up to Anna.\n",
      "    TARGET: Mentre Betsy le versava il tè, Vronskij si avvicinò ad Anna.\n",
      " PREDICTED: Mentre Betsy le versava il tè , Vronskij si avvicinò ad Anna .\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: 'Do not think too badly of me, Kostya!' and his voice trembled.\n",
      "    TARGET: — Tuttavia non serbarmi rancore, Kostja! — e la voce gli tremò.\n",
      " PREDICTED: — Tuttavia non serbarmi rancore , Kostja ! — e la voce gli tremò .\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: I was surprised to see the fellow so well pleased. “You fool,” says I, “he will eat you up.”—“Eatee me up! eatee me up!” says Friday, twice over again; “me eatee him up; me makee you good laugh; you all stay here, me show you good laugh.”\n",
      "    TARGET: Tanta giocondità del gagliardo mi parea fuor di proposito e mi sorprese. — «Pezzo di matto, gli dissi, ti mangia in un boccone! — Mangiar me in boccone! me in boccone! ripete Venerdì. Me mangiar lui! me dar a voi bel ridere.\n",
      " PREDICTED: Tanta del gagliardo mi parea fuor di proposito e mi sorprese . — « di matto , gli dissi , ti mangia in un boccone ! — me in boccone ! me in boccone ! ripete Venerdì . Me mangiar lui ! me dar a voi bel ridere !»\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# RUN THE VALIDATION\n",
    "run_validation(model, val_dataloader, tokenizer_src, tokenizer_tgt, config['seq_len'], device, lambda msg: print(msg), 0, None, num_examples=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gaussian_splatting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
